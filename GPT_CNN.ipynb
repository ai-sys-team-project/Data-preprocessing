{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m278-l0gkIbN",
        "outputId": "74ccb035-c24e-4fc4-d818-777a62ecb6e4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8liyPtySq7cK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NuU7Ap_nkFdt"
      },
      "outputs": [],
      "source": [
        "class EmbeddingDataset(Dataset):\n",
        "    def __init__(self, embeddings, labels):\n",
        "        self.embeddings = embeddings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self): # length of the dataset\n",
        "      return len(self.embeddings)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      embedding = self.embeddings[idx]\n",
        "      label = self.labels[idx]\n",
        "      return torch.tensor(embedding, dtype=torch.float32), torch.tensor(label, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "raljRzzvkFdt"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self, input_dim):\n",
        "    super(CNN, self).__init__()\n",
        "    self.conv1 = nn.Conv1d(1, 128, kernel_size=3, padding=1) # Convolutional layer: 1 input channel, 128 output channels, 3x3 kernel size\n",
        "    self.pool = nn.AdaptiveMaxPool1d(1) # Adaptive max pooling layer: 1 output channel\n",
        "    self.fc1 = nn.Linear(128, 64) # first fully connected layer: 128 input features, 64 output features\n",
        "    self.fc2 = nn.Linear(64, 1) # second fully connected layer: 64 input features, 1 output feature\n",
        "    self.dropout = nn.Dropout(0.5) # dropout layer with 0.5 dropout rate\n",
        "    # what is the dropout layer? 드롭아웃은 학습 중에 입력 단위의 일부를 무작위로 0으로 설정하여 과적합을 방지하는 데 도움이 됩니다.\n",
        "\n",
        "  def forward(self, x): # x: input tensor\n",
        "    x = self.conv1(x) # apply convolutional layer\n",
        "    x = torch.relu(x)\n",
        "    x = self.pool(x) # pool: apply pooling layer # pooling layer: reduce the size of the input tensor\n",
        "    x = x.view(-1, 128) # flatten the output tensor\n",
        "    x = self.fc1(x)\n",
        "    x = torch.relu(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.fc2(x)\n",
        "    return torch.sigmoid(x) # # 이진 분류를 위한 sigmoid 활성화 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2uAkiHIBkFdt"
      },
      "outputs": [],
      "source": [
        "embeddings = np.loadtxt('/content/drive/MyDrive/grad/ai-system/data/embeddings.csv', delimiter=',')\n",
        "\n",
        "data = pd.read_excel('/content/drive/MyDrive/grad/ai-system/data/에타 1차 라벨링.xlsx')\n",
        "labels = data['label'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Hrf6NYo_kFdt"
      },
      "outputs": [],
      "source": [
        "# Dataset 및 DataLoader 생성\n",
        "dataset = EmbeddingDataset(embeddings, labels)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# DataLeader를 사용해 학습 및 테스트 데이터셋을 로드\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# 모델, 손실 함수, 옵티마이저 정의\n",
        "input_dim = embeddings.shape[1]\n",
        "model = CNN(input_dim) # CNN 모델 초기화\n",
        "criterion = nn.BCELoss() # binary cross-entropy loss function 이진 분류를 위한 손실 함수\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001) # Adam optimizer # lr = learning rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMtQ_yl_kFdu",
        "outputId": "7407e8ab-4b4c-4795-a1f7-dfaf7b9cb12e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.7442\n",
            "Epoch [2/10], Loss: 0.7228\n",
            "Epoch [3/10], Loss: 0.6786\n",
            "Epoch [4/10], Loss: 0.6394\n",
            "Epoch [5/10], Loss: 0.6662\n",
            "Epoch [6/10], Loss: 0.8038\n",
            "Epoch [7/10], Loss: 0.5645\n",
            "Epoch [8/10], Loss: 0.6289\n",
            "Epoch [9/10], Loss: 0.5952\n",
            "Epoch [10/10], Loss: 0.5693\n"
          ]
        }
      ],
      "source": [
        "# 모델 학습\n",
        "num_epochs = 10\n",
        "model.train() # set the model to training mode\n",
        "for epoch in range(num_epochs):\n",
        "  for embeddings_batch, labels_batch in train_loader:\n",
        "    embeddings_batch = embeddings_batch.unsqueeze(1) # (batch_size, 1, input_dim)으로 차원 확장\n",
        "    outputs = model(embeddings_batch) # 모델을 사용하여 예측 생성\n",
        "    loss = criterion(outputs.squeeze(), labels_batch) # 손실 계산\n",
        "\n",
        "    optimizer.zero_grad() # 옵티마이저의 그래디언트 초기화\n",
        "    loss.backward()       # 역전파 수행\n",
        "    optimizer.step()      # 가중치 갱신\n",
        "  print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFHEpAOPkFdu",
        "outputId": "1150732e-2dcb-458c-b7e1-39b646424242"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5908175594039469\n",
            "F1 Score (Macro): 0.37139240506329113\n",
            "F1 Score (Micro): 0.5908175594039469\n"
          ]
        }
      ],
      "source": [
        "# 모델 평가\n",
        "model.eval() # set the model to evaluation mode\n",
        "y_true = []\n",
        "y_pred = []\n",
        "with torch.no_grad(): # 평가 중에는 그래디언트를 계산하지 않음\n",
        "  for embeddings_batch, labels_batch in test_loader:\n",
        "    embeddings_batch = embeddings_batch.unsqueeze(1)\n",
        "    outputs = model(embeddings_batch)\n",
        "    predicted = (outputs.squeeze() > 0.5).float() # 0.5보다 크면 1, 아니면 0으로 예측\n",
        "    y_true.extend(labels_batch.numpy())\n",
        "    y_pred.extend(predicted.numpy())\n",
        "\n",
        "# 평가 지표 계산\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "f1_micro = f1_score(y_true, y_pred, average='micro')\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'F1 Score (Macro): {f1_macro}')\n",
        "print(f'F1 Score (Micro): {f1_micro}')\n",
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}