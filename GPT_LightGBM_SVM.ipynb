{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8liyPtySq7cK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from openai import OpenAI\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten\n",
        "\n",
        "import lightgbm as lgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgutCNDLqiIj",
        "outputId": "0ba0be39-d35b-4313-d158-77ce4ac13c81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pYGHSiwSry4C"
      },
      "outputs": [],
      "source": [
        "client = OpenAI(\n",
        "  api_key='API Key',  # this is also the default, it can be omitted\n",
        ")\n",
        "\n",
        "data = pd.read_excel('/content/drive/MyDrive/grad/ai-system/data/에타 1차 라벨링.xlsx')\n",
        "texts = data['merged'].tolist()\n",
        "labels = data['label'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "02fSubq-qESx"
      },
      "outputs": [],
      "source": [
        "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
        "    if not isinstance(text, str):\n",
        "        text = str(text)\n",
        "    text = text.replace('\\n', ' ')\n",
        "    return client.embeddings.create(input=[text], model=model).data[0].embedding\n",
        "\n",
        "\n",
        "embeddings = [get_embedding(text) for text in texts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZHWachjfqgl9"
      },
      "outputs": [],
      "source": [
        "embeddings_array = np.array(embeddings)\n",
        "np.savetxt('/content/drive/MyDrive/grad/ai-system/data/test.csv', embeddings_array, delimiter=',')\n",
        "X_train, X_test, y_train, y_test = train_test_split(embeddings, labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pimzpYu0qgmA"
      },
      "source": [
        "## LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HqWgmb3659vt"
      },
      "outputs": [],
      "source": [
        "X_train_lgb = np.array(X_train)\n",
        "X_test_lgb = np.array(X_test)\n",
        "\n",
        "d_train = lgb.Dataset(X_train_lgb, label=y_train)\n",
        "d_test = lgb.Dataset(X_test_lgb, label=y_test, reference=d_train)\n",
        "\n",
        "params = {\n",
        "    'objective': 'binary',\n",
        "    'metric': 'binary_logloss',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'learning_rate': 0.0001,\n",
        "    'num_leaves': 31,\n",
        "    'min_child_samples': 20,\n",
        "    'colsample_bytree': 0.7,\n",
        "    'min_child_weight': 0.001,\n",
        "    'subsample_for_bin': 200000,\n",
        "    'reg_alpha': 0.1,\n",
        "    'reg_lambda': 0.1\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "i_fbZrbaqgmA",
        "outputId": "148d80fd-e6a9-448c-e195-8bc7d1d37b75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 4118, number of negative: 5810\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.894661 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 391680\n",
            "[LightGBM] [Info] Number of data points in the train set: 9928, number of used features: 1536\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.414786 -> initscore=-0.344213\n",
            "[LightGBM] [Info] Start training from score -0.344213\n",
            "LightGBM Accuracy: 0.5932339911397503\n",
            "LightGBM F1 score (macro): 0.3723458038422649\n",
            "LightGBM F1 score (micro): 0.5932339911397503\n"
          ]
        }
      ],
      "source": [
        "\n",
        "lgb_model = lgb.train(\n",
        "    params,\n",
        "    d_train,\n",
        "    valid_sets=[d_train, d_test],\n",
        "    num_boost_round=500,\n",
        "    )\n",
        "\n",
        "\n",
        "y_pred_lgb = lgb_model.predict(X_test, num_iteration=lgb_model.best_iteration)\n",
        "y_pred_lgb = (y_pred_lgb >= 0.5).astype(int)\n",
        "accuracy_lgb = accuracy_score(y_test, y_pred_lgb)\n",
        "f1_macro_lgb = f1_score(y_test, y_pred_lgb, average='macro')\n",
        "f1_micro_lgb = f1_score(y_test, y_pred_lgb, average='micro')\n",
        "\n",
        "print(f'LightGBM Accuracy: {accuracy_lgb}')\n",
        "print(f'LightGBM F1 score (macro): {f1_macro_lgb}')\n",
        "print(f'LightGBM F1 score (micro): {f1_micro_lgb}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5dIQHTkqgl-"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlxpfZOYqgl-",
        "outputId": "57ab96f9-9255-4bf6-c23e-ebf1acb8857a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7885622231171969\n",
            "F1 score (macro): 0.7672098125195879\n",
            "F1 score (micro): 0.7885622231171969\n"
          ]
        }
      ],
      "source": [
        "clf = SVC()\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred_svc = clf.predict(X_test)\n",
        "accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
        "f1_macro_svc = f1_score(y_test, y_pred_svc, average='macro')\n",
        "f1_micro_svc = f1_score(y_test, y_pred_svc, average='micro')\n",
        "\n",
        "print(f'SVC Accuracy: {accuracy_svc}')\n",
        "print(f'SVC F1 score (macro): {f1_macro_svc}')\n",
        "print(f'SVC F1 score (micro): {f1_micro_svc}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
