# Data-preprocessing 

codes for data preprocessing

## Embedding method - classifying method: (accuracy/f1 macro score)

![image](https://github.com/ai-sys-team-project/Data-preprocessing/assets/136441326/5aeb073e-c85c-4fde-9c44-3cbf73e2946c)


-모종의 이유로 LightGBM이 거의 학습이 안 된다. parameter도 수정해봤으나 결과는 동일했다. 
## Bert model
Klue-BERT-base:

KLUE BERT base is a pre-trained BERT model specifically designed for the Korean language. The developers created KLUE BERT base as part of the Korean Language Understanding Evaluation (KLUE) Benchmark initiative to enhance the performance of natural language processing tasks in Korean.


## GPT model
OpenAI Ada v2

